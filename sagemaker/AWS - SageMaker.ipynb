{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8b64ba3",
   "metadata": {},
   "source": [
    "# Deploy Inference Pipeline with Scikit-learn preprocessor and classifier to AWS with SageMaker\n",
    "\n",
    "The goal is to deploy the ML Pipeline[Preprocessor, classifaier] to the cloud. For that I will use `Sagemaker Scikit-learn container` for Preprocessor and `SageMaker XGBoost algorithm container` for classifaier.\n",
    "\n",
    "## Define Sagemaker session and role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c7d0ac2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# Get a SageMaker-compatible role used by this Notebook Instance.\n",
    "role = get_execution_role()\n",
    "\n",
    "# S3 prefix\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"Scikit-DefaultPredictor-pipeline\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a2da2ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sagemaker-eu-central-1-918203234730',\n",
       " 'Scikit-DefaultPredictor-pipeline',\n",
       " 'arn:aws:iam::918203234730:role/administrator')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket, prefix, role"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39a2358",
   "metadata": {},
   "source": [
    "## Preprocessing data and training the model\n",
    "### Upload the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "73deb88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIRECTORY = \"data\"\n",
    "\n",
    "train_input = sagemaker_session.upload_data(\n",
    "    path=\"{}/{}\".format(WORK_DIRECTORY, \"train.csv\"),\n",
    "    bucket=bucket,\n",
    "    key_prefix=\"{}/{}\".format(prefix, \"train\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97defe33",
   "metadata": {},
   "source": [
    "#### Training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33bc2e66",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# featurizer_remote.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "from io import StringIO\n",
    "import argparse\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sagemaker_containers.beta.framework import (\n",
    "    content_types, encoders, env, modules, transformer, worker)\n",
    "\n",
    "feature_columns_names = ['uuid','default', 'account_amount_added_12_24m', 'account_days_in_dc_12_24m',\n",
    "                       'account_days_in_rem_12_24m', 'account_days_in_term_12_24m',\n",
    "                       'account_incoming_debt_vs_paid_0_24m', 'account_status',\n",
    "                       'account_worst_status_0_3m', 'account_worst_status_12_24m',\n",
    "                       'account_worst_status_3_6m', 'account_worst_status_6_12m', 'age',\n",
    "                       'avg_payment_span_0_12m', 'avg_payment_span_0_3m', 'merchant_category',\n",
    "                       'merchant_group', 'has_paid', 'max_paid_inv_0_12m',\n",
    "                       'max_paid_inv_0_24m', 'name_in_email',\n",
    "                       'num_active_div_by_paid_inv_0_12m', 'num_active_inv',\n",
    "                       'num_arch_dc_0_12m', 'num_arch_dc_12_24m', 'num_arch_ok_0_12m',\n",
    "                       'num_arch_ok_12_24m', 'num_arch_rem_0_12m',\n",
    "                       'num_arch_written_off_0_12m', 'num_arch_written_off_12_24m',\n",
    "                       'num_unpaid_bills', 'status_last_archived_0_24m',\n",
    "                       'status_2nd_last_archived_0_24m', 'status_3rd_last_archived_0_24m',\n",
    "                       'status_max_archived_0_6_months', 'status_max_archived_0_12_months',\n",
    "                       'status_max_archived_0_24_months', 'recovery_debt',\n",
    "                       'sum_capital_paid_account_0_12m', 'sum_capital_paid_account_12_24m',\n",
    "                       'sum_paid_inv_0_12m', 'time_hours', 'worst_status_active_inv']\n",
    "\n",
    "feature_columns_dtype = {'uuid': \"object\", 'default': \"float64\", 'account_amount_added_12_24m' : \"int64\", 'account_days_in_dc_12_24m' : \"float64\", 'account_days_in_rem_12_24m' : \"float64\", \n",
    "                        'account_days_in_term_12_24m' : \"float64\", 'account_incoming_debt_vs_paid_0_24m' : \"float64\", 'account_status' : \"float64\", \n",
    "                        'account_worst_status_0_3m' : \"float64\", 'account_worst_status_12_24m' : \"float64\", 'account_worst_status_3_6m' : \"float64\", \n",
    "                        'account_worst_status_6_12m' : \"float64\", 'age' : \"int64\", 'avg_payment_span_0_12m' : \"float64\", 'avg_payment_span_0_3m' : \"float64\", \n",
    "                        'merchant_category' : \"object\", 'merchant_group' : \"object\", 'has_paid' : \"bool\", 'max_paid_inv_0_12m' : \"float64\", \n",
    "                        'max_paid_inv_0_24m' : \"float64\", 'name_in_email' : \"object\", 'num_active_div_by_paid_inv_0_12m' : \"float64\", 'num_active_inv' : \"int64\", \n",
    "                        'num_arch_dc_0_12m' : \"int64\", 'num_arch_dc_12_24m' : \"int64\", 'num_arch_ok_0_12m' : \"int64\", 'num_arch_ok_12_24m' : \"int64\", \n",
    "                        'num_arch_rem_0_12m' : \"int64\", 'num_arch_written_off_0_12m' : \"float64\", 'num_arch_written_off_12_24m' : \"float64\", 'num_unpaid_bills' : \"int64\", \n",
    "                        'status_last_archived_0_24m' : \"int64\", 'status_2nd_last_archived_0_24m' : \"int64\", 'status_3rd_last_archived_0_24m' : \"int64\", \n",
    "                        'status_max_archived_0_6_months' : \"int64\", 'status_max_archived_0_12_months' : \"int64\", 'status_max_archived_0_24_months' : \"int64\", \n",
    "                        'recovery_debt' : \"int64\", 'sum_capital_paid_account_0_12m' : \"int64\", 'sum_capital_paid_account_12_24m' : \"int64\", 'sum_paid_inv_0_12m' : \"int64\", \n",
    "                        'time_hours' : \"float64\", 'worst_status_active_inv' : \"float64\"}\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Sagemaker specific arguments. Defaults are set in the environment variables.\n",
    "    parser.add_argument('--output-data-dir', type=str, default=os.environ['SM_OUTPUT_DATA_DIR'])\n",
    "    parser.add_argument('--model-dir', type=str, default=os.environ['SM_MODEL_DIR'])\n",
    "    parser.add_argument('--train', type=str, default=os.environ['SM_CHANNEL_TRAIN'])\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Take the set of files and read them all into a single pandas dataframe\n",
    "    input_files = [ os.path.join(args.train, file) for file in os.listdir(args.train) ]\n",
    "    if len(input_files) == 0:\n",
    "        raise ValueError(('There are no files in {}.\\n' +\n",
    "                          'This usually indicates that the channel ({}) was incorrectly specified,\\n' +\n",
    "                          'the data specification in S3 was incorrectly specified or the role specified\\n' +\n",
    "                          'does not have permission to access the data.').format(args.train, \"train\"))\n",
    "\n",
    "    raw_data = [pd.read_csv(\n",
    "                file, \n",
    "                header=None, \n",
    "                sep = \";\",\n",
    "                names=feature_columns_names) for file in input_files]\n",
    "\n",
    "    train = pd.concat(raw_data)\n",
    "    train = train.set_index(\"uuid\")\n",
    "\n",
    "    # define features\n",
    "    categorical_low_card = [col for col in train.columns if col.find(\"status\") != -1]\n",
    "    categorical_high_card = [\"merchant_category\", \"merchant_group\", \"name_in_email\"]\n",
    "    binary = [\"has_paid\"]\n",
    "    numerical = list(set(train.columns) - set(categorical_low_card + categorical_high_card + binary) - set(['default']))\n",
    "\n",
    "    # Preprocessing pipeline\n",
    "    # Numeric features transforming Pipeline\n",
    "    num_transformer = Pipeline(steps=[\n",
    "            ('num_imputer', SimpleImputer(strategy=\"median\")),\n",
    "            ('scaler', StandardScaler())\n",
    "        ])\n",
    "    # Categorical features transforming Pipeline\n",
    "    cat_low_card_transformer = Pipeline(steps=[\n",
    "        ('cat_low_imputer', SimpleImputer(strategy=\"most_frequent\"))\n",
    "    ])\n",
    "\n",
    "    cat_high_card_transformer = Pipeline(steps=[\n",
    "        ('cat_high_imputer', OrdinalEncoder())\n",
    "    ])\n",
    "\n",
    "    # Binary features transforming Pipeline\n",
    "    binary_transformer = Pipeline(steps=[\n",
    "        ('ordinal', OrdinalEncoder())\n",
    "    ])\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', num_transformer, numerical),\n",
    "            ('cat_low_card', cat_low_card_transformer, categorical_low_card),\n",
    "            ('cat_high_card', cat_high_card_transformer, categorical_high_card),\n",
    "            ('binary', binary_transformer, binary)\n",
    "        ])\n",
    "    \n",
    "    preprocessor.fit(train)\n",
    "    \n",
    "    joblib.dump(preprocessor, os.path.join(args.model_dir, \"preprocessor.joblib\"))\n",
    "\n",
    "    print(\"saved model!\")\n",
    "\n",
    "    \n",
    "def input_fn(input_data, content_type):\n",
    "    \"\"\"Parse input data\n",
    "    \"\"\"\n",
    "    if content_type == 'text/csv':\n",
    "        # Read the raw input data as CSV.\n",
    "        df = pd.read_csv(StringIO(input_data))\n",
    "\n",
    "        return df\n",
    "    else:\n",
    "        raise ValueError(\"{} not supported by script!\".format(content_type))\n",
    "\n",
    "\n",
    "def output_fn(prediction, accept):\n",
    "    \"\"\"Format prediction output\n",
    "    \"\"\"\n",
    "    if accept == \"application/json\":\n",
    "        instances = []\n",
    "        for row in prediction.tolist():\n",
    "            instances.append({\"features\": row})\n",
    "\n",
    "        json_output = {\"instances\": instances}\n",
    "\n",
    "        return worker.Response(json.dumps(json_output), mimetype=accept)\n",
    "    elif accept == 'text/csv':\n",
    "        return worker.Response(encoders.encode(prediction, accept), mimetype=accept)\n",
    "    else:\n",
    "        raise RuntimeException(\"{} accept type is not supported by this script.\".format(accept))\n",
    "        \n",
    "        \n",
    "def predict_fn(input_data, model):\n",
    "    \"\"\"Preprocess input data\n",
    "\n",
    "    The model is a preprocessor = use .transform().\n",
    "    \"\"\"\n",
    "    features = model.transform(input_data)\n",
    "\n",
    "    if label_column in input_data:\n",
    "        # Return the label (as the first column) and the set of features.\n",
    "        return np.insert(features, 0, input_data[label_column], axis=1)\n",
    "    else:\n",
    "        # Return only the set of features\n",
    "        return features\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"Deserialize fitted model\n",
    "    \"\"\"\n",
    "    preprocessor = joblib.load(os.path.join(model_dir, \"preprocessor.joblib\"))\n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052f0d7c",
   "metadata": {},
   "source": [
    "## Create SageMaker Scikit Estimator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3b2013e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "FRAMEWORK_VERSION = \"0.23-1\"\n",
    "script_path = \"featurizer_remote.py\"\n",
    "\n",
    "sklearn_preprocessor = SKLearn(\n",
    "    entry_point=script_path,\n",
    "    role=role,\n",
    "    framework_version=FRAMEWORK_VERSION,\n",
    "    instance_type=\"ml.c4.xlarge\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "deee06cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-24 16:06:56 Starting - Starting the training job...ProfilerReport-1629821209: InProgress\n",
      "..............................\n",
      "2021-08-24 16:12:28 Starting - Launching requested ML instances..................\n",
      "2021-08-24 16:15:43 Starting - Preparing the instances for training..............................\n",
      "2021-08-24 16:20:44 Downloading - Downloading input data............\n",
      "2021-08-24 16:22:47 Training - Downloading the training image..\u001b[34m2021-08-24 16:23:10,176 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2021-08-24 16:23:10,178 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-08-24 16:23:10,188 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2021-08-24 16:23:10,675 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-08-24 16:23:10,686 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-08-24 16:23:10,698 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-08-24 16:23:10,707 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-scikit-learn-2021-08-24-16-06-49-444\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-eu-central-1-918203234730/sagemaker-scikit-learn-2021-08-24-16-06-49-444/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"featurizer_remote\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"featurizer_remote.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=featurizer_remote.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=featurizer_remote\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-eu-central-1-918203234730/sagemaker-scikit-learn-2021-08-24-16-06-49-444/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2021-08-24-16-06-49-444\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-central-1-918203234730/sagemaker-scikit-learn-2021-08-24-16-06-49-444/source/sourcedir.tar.gz\",\"module_name\":\"featurizer_remote\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"featurizer_remote.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python featurizer_remote.py\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34msys:1: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,17,18,19,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42) have mixed types.Specify dtype option on import or set low_memory=False.\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"featurizer_remote.py\", line 96, in <module>\n",
      "    preprocessor.fit(train)\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py\", line 494, in fit\n",
      "    self.fit_transform(X, y=y)\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py\", line 531, in fit_transform\n",
      "    result = self._fit_transform(X, y, _fit_transform_one)\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py\", line 467, in _fit_transform\n",
      "    self._iter(fitted=fitted, replace_strings=True), 1))\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/sklearn/pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/sklearn/pipeline.py\", line 367, in fit_transform\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/sklearn/pipeline.py\", line 296, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/joblib/memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/sklearn/pipeline.py\", line 740, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/sklearn/base.py\", line 690, in fit_transform\n",
      "    return self.fit(X, **fit_params).transform(X)\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/sklearn/impute/_base.py\", line 277, in fit\n",
      "    X = self._validate_input(X, in_fit=True)\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/sklearn/impute/_base.py\", line 249, in _validate_input\n",
      "    raise new_ve from None\u001b[0m\n",
      "\u001b[34mValueError: Cannot use median strategy with non-numeric data:\u001b[0m\n",
      "\u001b[34mcould not convert string to float: 'num_active_div_by_paid_inv_0_12m'\u001b[0m\n",
      "\u001b[34m2021-08-24 16:23:13,531 sagemaker-containers ERROR    Reporting training FAILURE\u001b[0m\n",
      "\u001b[34m2021-08-24 16:23:13,531 sagemaker-containers ERROR    framework error: \u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_containers/_trainer.py\", line 84, in train\n",
      "    entrypoint()\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_sklearn_container/training.py\", line 39, in main\n",
      "    train(environment.Environment())\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_sklearn_container/training.py\", line 35, in train\n",
      "    runner_type=runner.ProcessRunnerType)\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_training/entry_point.py\", line 100, in run\n",
      "    wait, capture_error\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_training/process.py\", line 161, in run\n",
      "    cwd=environment.code_dir,\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_training/process.py\", line 81, in check_error\n",
      "    raise error_class(return_code=return_code, cmd=\" \".join(cmd), output=stderr)\u001b[0m\n",
      "\u001b[34msagemaker_training.errors.ExecuteUserScriptError: ExecuteUserScriptError:\u001b[0m\n",
      "\u001b[34mCommand \"/miniconda3/bin/python featurizer_remote.py\"\n",
      "\u001b[0m\n",
      "\u001b[34mExecuteUserScriptError:\u001b[0m\n",
      "\u001b[34mCommand \"/miniconda3/bin/python featurizer_remote.py\"\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-08-24 16:23:45 Training - Training image download completed. Training in progress.\n",
      "2021-08-24 16:24:25 Uploading - Uploading generated training model"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zj/l29x8njj1yncqvpwgkycthvw0000gp/T/ipykernel_3635/1284146144.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msklearn_preprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_input\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Envs/hf/lib/python3.9/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compilation_job_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/hf/lib/python3.9/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   1629\u001b[0m         \u001b[0;31m# If logs are requested, call logs_for_jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"None\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1631\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1632\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/hf/lib/python3.9/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type)\u001b[0m\n\u001b[1;32m   3624\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3626\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3628\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mLogState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJOB_COMPLETE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fit preprocessor\n",
    "sklearn_preprocessor.fit({\"train\": train_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb35b60",
   "metadata": {},
   "source": [
    "## Batch transform training data\n",
    "Use fitted preprocessor and batch transform to directly preprocess the raw data and store right back into s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd736bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a SKLearn Transformer from the trained SKLearn Estimator\n",
    "transformer = sklearn_preprocessor.transformer(\n",
    "    instance_count=1, instance_type=\"ml.m4.xlarge\", assemble_with=\"Line\", accept=\"text/csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31685e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess training input\n",
    "transformer.transform(train_input, content_type=\"text/csv\")\n",
    "print(\"Waiting for transform job: \" + transformer.latest_transform_job.job_name)\n",
    "transformer.wait()\n",
    "preprocessed_train = transformer.output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb3a15d",
   "metadata": {},
   "source": [
    "## Fit a Tree-based Model with the preprocessed data\n",
    "\n",
    "Take the preprocessed training data and fit XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e0932f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from sagemaker.debugger import Rule, rule_configs\n",
    "from sagemaker.session import TrainingInput\n",
    "\n",
    "\n",
    "s3_output_location='s3://{}/{}/{}'.format(bucket, prefix, 'xgboost_model')\n",
    "\n",
    "container=sagemaker.image_uris.retrieve(\"xgboost\", boto3.Session().region_name, \"1.2-1\")\n",
    "print(container)\n",
    "\n",
    "# Create an XGBoost estimator using the sagemaker.estimator.Estimator class\n",
    "\n",
    "xgb_estimator=sagemaker.estimator.Estimator(\n",
    "    image_uri=container,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    train_volume_size=5,\n",
    "    output_path=s3_output_location,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    rules=[Rule.sagemaker(rule_configs.create_xgboost_report())]\n",
    ")\n",
    "\n",
    "xgb_estimator.set_hyperparameters(\n",
    "    max_depth = 5,\n",
    "    eta = 0.2,\n",
    "    gamma = 4,\n",
    "    min_child_weight = 6,\n",
    "    subsample = 0.7,\n",
    "    objective = \"binary:logistic\",\n",
    "    num_round = 1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a965c179",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.session import TrainingInput\n",
    "\n",
    "xgb_train_data = sagemaker.inputs.TrainingInput(\n",
    "    preprocessed_train,\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=\"text/csv\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    ")\n",
    "\n",
    "data_channels = {\"train\": xgb_train_data}\n",
    "\n",
    "xgb_estimator.fit(inputs=data_channels, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a821ae0",
   "metadata": {},
   "source": [
    "## Serial Inference Pipeline with Scikit preprocessor and xgb\n",
    "\n",
    "Configure pipeline model with the fitted Scikit-learn inference model and the fitted xgd model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cf986c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "from sagemaker.pipeline import PipelineModel\n",
    "from time import gmtime, strftime\n",
    "\n",
    "timestamp_prefix = strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "scikit_learn_inferencee_model = sklearn_preprocessor.create_model()\n",
    "xgb_model = xgb_estimator.create_model()\n",
    "\n",
    "model_name = \"inference-pipeline-\" + timestamp_prefix\n",
    "endpoint_name = \"inference-pipeline-ep-\" + timestamp_prefix\n",
    "xgb_predictor = PipelineModel(\n",
    "    name=model_name, role=role, models=[scikit_learn_inferencee_model, xgb_model]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42db9e16",
   "metadata": {},
   "source": [
    "## Deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709de1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "# Serialize input data to a CSV-formatted string as XGBoost algorithm accepts input files in CSV format\n",
    "\n",
    "xgb_predictor.deploy(initial_instance_count=1, \n",
    "                instance_type=\"ml.c4.xlarge\", \n",
    "                endpoint_name=endpoint_name,\n",
    "                serializer=CSVSerializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1111c8c2",
   "metadata": {},
   "source": [
    "## Make a request to the pipeline endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62360ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "datapoint = \"0, 0.0, 0.0, 0.0, 0.00913, 1.0, 1.0, null, 1.0, 1.0, 20, 6.4, 5.25, 'Youthful Shoes & Clothing', 'Clothing & Shoes', true, 7225.0, 7225.0, 'F', 0.0, 0, 0, 0, 5, 0, 0, 0.0, 0.0, 1, 1, 1, 1, 1, 1, 1, 0, 8815, 0, 27157, 19.8955, null\"\n",
    "actual_default = 0\n",
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name, sagemaker_session=sagemaker_session, serializer=CSVSerializer()\n",
    ")\n",
    "\n",
    "print(predictor.predict(datapoint))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "hf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
